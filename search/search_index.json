{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Elastic ML Whitelist Guide","text":"<p>Welcome to the Elastic ML Whitelist Guide! This guide will walk you through creating and using a trained machine learning model to predict whether alerts in Elastic should be whitelisted or not.</p> <p></p>"},{"location":"#steps","title":"Steps","text":""},{"location":"#1-train-the-model-locally","title":"1. Train the Model Locally","text":"<p>Train a machine learning model using historical Elastic data. Preprocess data as needed before training the model. Save the trained model to a file (e.g., using <code>pickle</code>).</p>"},{"location":"#imports","title":"Imports","text":"<pre><code>import pandas as pd\nimport numpy as np \n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport hashlib\nfrom sklearn.inspection import permutation_importance\n</code></pre>"},{"location":"#cleaning-of-data","title":"Cleaning of Data","text":"<pre><code>def remove_hyphens_from_csv(file_name):\n# Read the CSV file\n    df = pd.read_csv(file_name)\n\n# Iterate through each column and remove hyphens\nfor column in df.columns:\n    df[column] = df[column].astype(str).str.replace('-', '')\n\n# Save the modified df to a new CSV file\ndf.to_csv('clean.csv', index=False)\n</code></pre>"},{"location":"#feature-encoding","title":"Feature Encoding","text":"<pre><code># Read data\ndf = pd.read_csv('clean.csv')\n\n# function that takes a row and hashes each value with the column name\ndef hash_row_values(row):\n    return [hash(f\"{col}_{value}\") for col, value in zip(row.index, row) if col != 'whitelist']\n\n# Apply the hash function to each column\nfor col in df.columns:\n    if col != 'whitelist':\n        df[col + '_hash'] = df.apply(lambda row: hash(f\"{col}_{row[col]}\"), axis=1)\n</code></pre>"},{"location":"#model-training","title":"Model Training","text":"<p><pre><code># Independant Variables\nX = df[['Features']]\n\n#Dependant Variable\ny = df[['What is being predicted']]\n</code></pre> <pre><code># Train Test Split\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n</code></pre> <pre><code># !--Random Forest Model--!\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nRmodel = RandomForestClassifier(n_estimators=100)\n\nRmodel.fit(X_train, y_train)\n\ny_pred = Rmodel.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)\n\nAccuracy: 0.9726027397260274\nPrecision: 0.9523809523809523\nRecall: 0.9523809523809523\nF1 Score: 0.9523809523809523\n</code></pre></p> <pre><code># Convert model into a .pkl file\n\nfrom joblib import dump\ndump(model, 'model.pkl')\n</code></pre>"},{"location":"#2-import-the-model-into-elasticsearch","title":"2. Import the Model into Elasticsearch","text":"<pre><code>import eland as ed\nfrom elasticsearch import Elasticsearch\nimport pickle\n\nes_client = Elasticsearch(\"http://localhost:9200\") \n</code></pre> <pre><code># Replace 'path/to/trained_model.pkl' with the path to saved model file\n\nwith open(\"path/to/trained_model.pkl\", \"rb\") as model_file:\n    model = pickle.load(model_file)\n\nmodel_id = \"imported-model-id\"\ned.ml.import_model(es_client, model, model_id)\n</code></pre>"},{"location":"#3-create-an-elasticsearch-ingest-pipeline-with-the-inference-processor","title":"3. Create an Elasticsearch Ingest Pipeline with the Inference Processor","text":"<pre><code>pipeline_id = \"whitelist-prediction-pipeline\"\n\npipeline_body = {\n\u00a0 \u00a0\"description\": \"Pipeline to predict if an alert should be whitelisted\",\n\u00a0 \u00a0\"processors\": [\n\u00a0 \u00a0 \u00a0 \u00a0{\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"script\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"lang\": \"painless\",\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"source\": \"\"\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0// custom script to apply feature encoding\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0def hash_value(col, value) {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0return Integer.toUnsignedLong((col + '_' + value).hashCode());\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0}\n\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0// Apply hashing to each field that has importance\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0ctx['field1_hash'] = hash_value('field1', ctx['field1']);\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0ctx['field2_hash'] = hash_value('field2', ctx['field2']);\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0// ... Add similar lines for all the other fields\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"\"\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0}\n\u00a0 \u00a0 \u00a0 \u00a0},\n\u00a0 \u00a0 \u00a0 \u00a0{\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"inference\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"model_id\": model_id,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"inference_config\": {\"classification\": {}},\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"field_map\": { # Dependant Variables\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"field1\": \"field1_hash\",\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"field2\": \"field2_hash\",\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0# ... Map the other fields as needed\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0},\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"target_field\": \"whitelist_prediction\", #Independant Variable\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0}\n\u00a0 \u00a0 \u00a0 \u00a0},\n\u00a0 \u00a0],\n}\n\nes_client.ingest.put_pipeline(id=pipeline_id, body=pipeline_body)\n</code></pre>"},{"location":"#4-create-a-new-pipeline-to-route-whitelisted-alerts-to-a-new-index","title":"4. Create a New Pipeline to Route Whitelisted Alerts to a New Index","text":"<pre><code>whitelisted_alerts_index = \"whitelisted-alerts\"\nnew_pipeline_id = \"route-to-whitelisted-index\"\n\nnew_pipeline_body = {\n\u00a0 \u00a0\"description\": \"Pipeline to route whitelisted alerts to a new index\",\n\u00a0 \u00a0\"processors\": [\n\u00a0 \u00a0 \u00a0 \u00a0{\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"conditional\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"if\": \"ctx.whitelist_prediction.class_name == '1'\",\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"processors\": [\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0{\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"index\": {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"index\": whitelisted_alerts_index,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0}\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0}\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0],\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0}\n\u00a0 \u00a0 \u00a0 \u00a0},\n\u00a0 \u00a0],\n}\n\nes_client.ingest.put_pipeline(id=new_pipeline_id, body=new_pipeline_body)\n</code></pre>"},{"location":"#5-configure-filebeat-or-logstash-to-use-the-new-pipeline","title":"5. Configure Filebeat or Logstash to Use the New Pipeline","text":""},{"location":"#filebeatyml","title":"filebeat.yml","text":"<pre><code>filebeat.inputs:\n- type: log\n  paths:\n    - /path/to/alert/logs/*.log\n  fields:\n    pipeline: \"route-to-whitelisted-index\"\n\noutput.elasticsearch:\n  hosts: [\"http://localhost:9200\"]\n  pipeline: \"%{[fields.pipeline]}\"\n</code></pre>"},{"location":"#logstashconf","title":"logstash.conf","text":"<pre><code>output {\n  elasticsearch {\n    hosts =&gt; [\"http://localhost:9200\"]\n    index =&gt; \"siem-index\"\n    pipeline =&gt; \"route-to-whitelisted-index\"\n  }\n}\n</code></pre>"},{"location":"#reference-links","title":"Reference Links","text":"<p>https://eland.readthedocs.io/en/v8.3.0/reference/api/eland.ml.MLModel.import_model.html</p> <p>https://eland.readthedocs.io/en/7.9.1a1/examples/introduction_to_eland_webinar.html#Machine-Learning-Demo</p> <p>https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html</p> <p>https://www.elastic.co/guide/en/elasticsearch/client/eland/current/overview.html</p> <p>https://www.youtube.com/watch?v=w8RwRO8gI_s&amp;pp=ygUNZWxhbmQgZWxhc3RpYw%3D%3D</p>"},{"location":"#terms","title":"Terms","text":""},{"location":"#an-inference-processor-is-part-of-the-elasticsearch-ingest-pipeline-that-allows-you-to-use-pre-trained-ml-models-to-enrich-data-during-indexing-so-itll-apply-the-ml-model-to-incoming-documents-and-add-the-models-prediction-results-as-new-fields-in-the-documents-before-they-are-stored-in-an-elastic-index","title":"An Inference Processor: is part of the Elasticsearch ingest pipeline that allows you to use pre-trained Ml Models to enrich data during indexing. So it'll apply the ML Model to incoming documents and add the model's prediction results as new fields in the documents before they are stored in an Elastic index.","text":""},{"location":"#feature-encoding-feature-encoding-is-the-process-of-converting-non-numeric-data-types-eg-categorical-or-textual-data-into-a-numerical-format-that-can-be-used-by-machine-learning-algorithms-many-machine-learning-algorithms-require-input-data-to-be-in-a-numerical-format-so-feature-encoding-is-a-critical-pre-processing-step-when-working-with-non-numeric-features","title":"Feature Encoding: Feature encoding is the process of converting non-numeric data types (e.g., categorical or textual data) into a numerical format that can be used by machine learning algorithms. Many machine learning algorithms require input data to be in a numerical format, so feature encoding is a critical pre-processing step when working with non-numeric features.","text":""},{"location":"#accuracy-accuracy-is-a-metric-used-to-evaluate-the-performance-of-a-classification-model-it-is-calculated-as-the-ratio-of-the-number-of-correct-predictions-to-the-total-number-of-predictions-made-in-other-words-it-measures-how-well-a-model-correctly-classifies-instances-in-the-dataset","title":"Accuracy: Accuracy is a metric used to evaluate the performance of a classification model. It is calculated as the ratio of the number of correct predictions to the total number of predictions made. In other words, it measures how well a model correctly classifies instances in the dataset.","text":""},{"location":"#precision-precision-is-a-measure-of-the-accuracy-of-positive-predictions-made-by-a-classification-model-it-is-calculated-as-the-ratio-of-true-positive-predictions-correctly-identified-positive-instances-to-the-sum-of-true-positive-and-false-positive-predictions-instances-incorrectly-identified-as-positive-high-precision-indicates-that-a-model-is-good-at-avoiding-false-positives","title":"Precision: Precision is a measure of the accuracy of positive predictions made by a classification model. It is calculated as the ratio of true positive predictions (correctly identified positive instances) to the sum of true positive and false positive predictions (instances incorrectly identified as positive). High precision indicates that a model is good at avoiding false positives.","text":""},{"location":"#recall-recall-also-known-as-sensitivity-or-true-positive-rate-is-a-measure-of-a-classification-models-ability-to-identify-all-the-relevant-instances-in-the-dataset-it-is-calculated-as-the-ratio-of-true-positive-predictions-to-the-sum-of-true-positive-and-false-negative-predictions-instances-incorrectly-identified-as-negative-high-recall-indicates-that-a-model-is-good-at-identifying-positive-instances-and-minimizing-false-negatives","title":"Recall: Recall, also known as sensitivity or true positive rate, is a measure of a classification model's ability to identify all the relevant instances in the dataset. It is calculated as the ratio of true positive predictions to the sum of true positive and false negative predictions (instances incorrectly identified as negative). High recall indicates that a model is good at identifying positive instances and minimizing false negatives.","text":""},{"location":"#f1-scorethe-f1-score-is-a-metric-that-combines-precision-and-recall-to-provide-a-single-measure-of-a-classification-models-performance-it-is-the-harmonic-mean-of-precision-and-recall-and-ranges-between-0-and-1-with-1-indicating-perfect-precision-and-recall-the-f1-score-is-particularly-useful-when-dealing-with-imbalanced-datasets-where-one-class-is-more-frequent-than-the-other-as-it-takes-into-account-both-false-positives-and-false-negatives-a-high-f1-score-indicates-that-the-model-has-a-good-balance-between-precision-and-recall","title":"F1 Score:The F1 Score is a metric that combines precision and recall to provide a single measure of a classification model's performance. It is the harmonic mean of precision and recall and ranges between 0 and 1, with 1 indicating perfect precision and recall. The F1 Score is particularly useful when dealing with imbalanced datasets, where one class is more frequent than the other, as it takes into account both false positives and false negatives. A high F1 Score indicates that the model has a good balance between precision and recall.","text":""}]}